{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bb63b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kaila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kaila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.bigdata_a3_utils import *\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# from utils.preprocessing import *\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2fcff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"custom_dataset\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a94090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0f1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_csv_path = \"custom_dataset/reviews.csv\"\n",
    "metadata_csv_path = \"custom_dataset/metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7a24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i, category in VALID_CATEGORIES:\n",
    "# for i, category in enumerate(tqdm(VALID_CATEGORIES, desc=\"Processing categories\")):\n",
    "#     print(f\"Processing {category}...\")\n",
    "\n",
    "#     try:\n",
    "#         review_dataset = load_dataset(\n",
    "#             \"McAuley-Lab/Amazon-Reviews-2023\", \n",
    "#             f\"raw_review_{category}\", \n",
    "#             trust_remote_code=True\n",
    "#         )\n",
    "\n",
    "#         review_df = pd.DataFrame(review_dataset['full'][:MAX_ROWS])\n",
    "\n",
    "#         review_df[\"category\"] = category \n",
    "        \n",
    "#         mode = 'w' if i == 0 else 'a'\n",
    "#         header = i == 0\n",
    "\n",
    "#         review_df.to_csv(reviews_csv_path, mode=mode, header=header, index=False)\n",
    "\n",
    "#         print(f\"Appended {len(review_df)} rows of {category} to {reviews_csv_path}.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading dataset for {category}: {e}\")\n",
    "    \n",
    "#     try:\n",
    "#         meta_dataset = load_dataset(\n",
    "#             \"McAuley-Lab/Amazon-Reviews-2023\", \n",
    "#             f\"raw_meta_{category}\", \n",
    "#             trust_remote_code=True\n",
    "#         )\n",
    "        \n",
    "#         # Convert to pandas DataFrame and limit to MAX_ROWS\n",
    "#         meta_df = pd.DataFrame(meta_dataset['full'][:MAX_ROWS])\n",
    "\n",
    "#         meta_df['category'] = category\n",
    "\n",
    "#         mode = 'w' if i == 0 else 'a'\n",
    "#         header = i == 0\n",
    "\n",
    "#         meta_df.to_csv(metadata_csv_path, mode=mode, header=header, index=False)\n",
    "#         print(f\"Loaded {len(meta_df)} rows of {category} metadata.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading dataset for {category}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509ec902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: All_Beauty\n",
      "  ✓ Appended 10000 reviews from All_Beauty to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   3%|▎         | 1/34 [00:11<06:14, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from All_Beauty to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Amazon_Fashion\n",
      "  ✓ Appended 10000 reviews from Amazon_Fashion to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   6%|▌         | 2/34 [00:17<04:22,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Amazon_Fashion to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Appliances\n",
      "  ✓ Appended 10000 reviews from Appliances to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   9%|▉         | 3/34 [00:24<04:04,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Appliances to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Arts_Crafts_and_Sewing\n",
      "  ✓ Appended 10000 reviews from Arts_Crafts_and_Sewing to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  12%|█▏        | 4/34 [00:32<03:50,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Arts_Crafts_and_Sewing to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Automotive\n",
      "  ✓ Appended 10000 reviews from Automotive to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  15%|█▍        | 5/34 [00:39<03:35,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Automotive to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Baby_Products\n",
      "  ✓ Appended 10000 reviews from Baby_Products to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  18%|█▊        | 6/34 [00:47<03:39,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Baby_Products to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Beauty_and_Personal_Care\n",
      "  ✓ Appended 10000 reviews from Beauty_and_Personal_Care to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  21%|██        | 7/34 [00:56<03:38,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Beauty_and_Personal_Care to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Books\n",
      "  ✓ Appended 10000 reviews from Books to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  24%|██▎       | 8/34 [01:05<03:37,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Books to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: CDs_and_Vinyl\n",
      "  ✓ Appended 10000 reviews from CDs_and_Vinyl to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  26%|██▋       | 9/34 [01:11<03:08,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from CDs_and_Vinyl to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Cell_Phones_and_Accessories\n",
      "  ✓ Appended 10000 reviews from Cell_Phones_and_Accessories to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  29%|██▉       | 10/34 [01:19<03:03,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Cell_Phones_and_Accessories to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Clothing_Shoes_and_Jewelry\n",
      "  ✓ Appended 10000 reviews from Clothing_Shoes_and_Jewelry to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  32%|███▏      | 11/34 [01:25<02:47,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Clothing_Shoes_and_Jewelry to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Digital_Music\n",
      "  ✓ Appended 10000 reviews from Digital_Music to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  35%|███▌      | 12/34 [01:30<02:22,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Digital_Music to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Electronics\n",
      "  ✓ Appended 10000 reviews from Electronics to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  38%|███▊      | 13/34 [01:38<02:28,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Electronics to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Gift_Cards\n",
      "  ✓ Appended 10000 reviews from Gift_Cards to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  41%|████      | 14/34 [01:41<01:55,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 1137 metadata records from Gift_Cards to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Grocery_and_Gourmet_Food\n",
      "  ✓ Appended 10000 reviews from Grocery_and_Gourmet_Food to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  44%|████▍     | 15/34 [01:48<01:56,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Grocery_and_Gourmet_Food to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Handmade_Products\n",
      "  ✓ Appended 10000 reviews from Handmade_Products to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  47%|████▋     | 16/34 [01:54<01:49,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Handmade_Products to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Health_and_Household\n",
      "  ✓ Appended 10000 reviews from Health_and_Household to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  50%|█████     | 17/34 [02:02<01:52,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Health_and_Household to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Health_and_Personal_Care\n",
      "  ✓ Appended 10000 reviews from Health_and_Personal_Care to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  53%|█████▎    | 18/34 [02:07<01:42,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Health_and_Personal_Care to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Home_and_Kitchen\n",
      "  ✓ Appended 10000 reviews from Home_and_Kitchen to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  56%|█████▌    | 19/34 [02:16<01:47,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Home_and_Kitchen to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Industrial_and_Scientific\n",
      "  ✓ Appended 10000 reviews from Industrial_and_Scientific to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  59%|█████▉    | 20/34 [02:24<01:42,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Industrial_and_Scientific to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Kindle_Store\n",
      "  ✓ Appended 10000 reviews from Kindle_Store to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  62%|██████▏   | 21/34 [02:34<01:47,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Kindle_Store to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Magazine_Subscriptions\n",
      "  ✓ Appended 10000 reviews from Magazine_Subscriptions to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  65%|██████▍   | 22/34 [02:37<01:19,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 3391 metadata records from Magazine_Subscriptions to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Movies_and_TV\n",
      "  ✓ Appended 10000 reviews from Movies_and_TV to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  68%|██████▊   | 23/34 [02:43<01:09,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Movies_and_TV to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Musical_Instruments\n",
      "  ✓ Appended 10000 reviews from Musical_Instruments to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  71%|███████   | 24/34 [02:51<01:07,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Musical_Instruments to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Office_Products\n",
      "  ✓ Appended 10000 reviews from Office_Products to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  74%|███████▎  | 25/34 [02:59<01:05,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Office_Products to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Patio_Lawn_and_Garden\n",
      "  ✓ Appended 10000 reviews from Patio_Lawn_and_Garden to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  76%|███████▋  | 26/34 [03:08<01:00,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Patio_Lawn_and_Garden to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Pet_Supplies\n",
      "  ✓ Appended 10000 reviews from Pet_Supplies to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  79%|███████▉  | 27/34 [03:16<00:55,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Pet_Supplies to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Software\n",
      "  ✓ Appended 10000 reviews from Software to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  82%|████████▏ | 28/34 [03:23<00:45,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Software to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Sports_and_Outdoors\n",
      "  ✓ Appended 10000 reviews from Sports_and_Outdoors to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  85%|████████▌ | 29/34 [03:30<00:37,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Sports_and_Outdoors to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Subscription_Boxes\n",
      "  ✓ Appended 10000 reviews from Subscription_Boxes to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  88%|████████▊ | 30/34 [03:33<00:24,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 641 metadata records from Subscription_Boxes to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Tools_and_Home_Improvement\n",
      "  ✓ Appended 10000 reviews from Tools_and_Home_Improvement to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  91%|█████████ | 31/34 [03:42<00:20,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Tools_and_Home_Improvement to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Toys_and_Games\n",
      "  ✓ Appended 10000 reviews from Toys_and_Games to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  94%|█████████▍| 32/34 [03:50<00:14,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Toys_and_Games to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Video_Games\n",
      "  ✓ Appended 10000 reviews from Video_Games to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:  97%|█████████▋| 33/34 [03:58<00:07,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Video_Games to custom_dataset/metadata.csv\n",
      "\n",
      "Processing category: Unknown\n",
      "  ✓ Appended 10000 reviews from Unknown to custom_dataset/reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████| 34/34 [04:04<00:00,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Appended 10000 metadata records from Unknown to custom_dataset/metadata.csv\n",
      "\n",
      "All categories processed!\n",
      "Review data saved to: custom_dataset/reviews.csv\n",
      "Metadata saved to: custom_dataset/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_review_df = None\n",
    "first_meta_df = None\n",
    "\n",
    "# Process each category\n",
    "for category in tqdm(VALID_CATEGORIES, desc=\"Processing categories\"):\n",
    "    print(f\"\\nProcessing category: {category}\")\n",
    "    \n",
    "    # Process review data\n",
    "    try:\n",
    "        # Use streaming mode with iterable dataset\n",
    "        review_dataset = load_dataset(\n",
    "            \"McAuley-Lab/Amazon-Reviews-2023\", \n",
    "            f\"raw_review_{category}\", \n",
    "            trust_remote_code=True,\n",
    "            split=\"full\",\n",
    "            streaming=True\n",
    "        )\n",
    "        \n",
    "        # Create an iterator for the dataset\n",
    "        review_iter = iter(review_dataset)\n",
    "        \n",
    "        # Collect reviews into a list (up to MAX_ROWS)\n",
    "        reviews = []\n",
    "        count = 0\n",
    "        \n",
    "        for item in review_iter:\n",
    "            if count >= MAX_ROWS:\n",
    "                break\n",
    "                \n",
    "            # Create a new dictionary instead of modifying the item in-place\n",
    "            review_item = dict(item)\n",
    "            review_item['category'] = category\n",
    "            reviews.append(review_item)\n",
    "            count += 1\n",
    "            \n",
    "            # Process in batches to conserve memory\n",
    "            if len(reviews) >= 1000 or count >= MAX_ROWS:\n",
    "                review_df = pd.DataFrame(reviews)\n",
    "                \n",
    "                # Check if this is the first batch we're writing\n",
    "                if first_review_df is None:\n",
    "                    review_df.to_csv(reviews_csv_path, mode='w', header=True, index=False)\n",
    "                    first_review_df = True\n",
    "                else:\n",
    "                    review_df.to_csv(reviews_csv_path, mode='a', header=False, index=False)\n",
    "                \n",
    "                # Clear the batch\n",
    "                reviews = []\n",
    "        \n",
    "        print(f\"  ✓ Appended {count} reviews from {category} to {reviews_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing reviews for {category}: {str(e)}\")\n",
    "    \n",
    "    # Process metadata\n",
    "    try:\n",
    "        # Use streaming mode with iterable dataset\n",
    "        meta_dataset = load_dataset(\n",
    "            \"McAuley-Lab/Amazon-Reviews-2023\", \n",
    "            f\"raw_meta_{category}\", \n",
    "            trust_remote_code=True,\n",
    "            split=\"full\",\n",
    "            streaming=True\n",
    "        )\n",
    "        \n",
    "        # Create an iterator for the dataset\n",
    "        meta_iter = iter(meta_dataset)\n",
    "        \n",
    "        # Collect metadata into a list (up to MAX_ROWS)\n",
    "        metadata = []\n",
    "        count = 0\n",
    "        \n",
    "        for item in meta_iter:\n",
    "            if count >= MAX_ROWS:\n",
    "                break\n",
    "                \n",
    "            # Create a new dictionary instead of modifying the item in-place\n",
    "            meta_item = dict(item)\n",
    "            meta_item['category'] = category\n",
    "            metadata.append(meta_item)\n",
    "            count += 1\n",
    "            \n",
    "            # Process in batches to conserve memory\n",
    "            if len(metadata) >= 1000 or count >= MAX_ROWS:\n",
    "                meta_df = pd.DataFrame(metadata)\n",
    "                \n",
    "                # Check if this is the first batch we're writing\n",
    "                if first_meta_df is None:\n",
    "                    meta_df.to_csv(metadata_csv_path, mode='w', header=True, index=False)\n",
    "                    first_meta_df = True\n",
    "                else:\n",
    "                    meta_df.to_csv(metadata_csv_path, mode='a', header=False, index=False)\n",
    "                \n",
    "                # Clear the batch\n",
    "                metadata = []\n",
    "        \n",
    "        print(f\"  ✓ Appended {count} metadata records from {category} to {metadata_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing metadata for {category}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nAll categories processed!\")\n",
    "print(f\"Review data saved to: {reviews_csv_path}\")\n",
    "print(f\"Metadata saved to: {metadata_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7856125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Deleting Hugging Face cache at: C:\\Users\\kaila\\.cache\\huggingface\\datasets\n",
      "[SUCCESS] Cache directory deleted.\n"
     ]
    }
   ],
   "source": [
    "delete_cache_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e06e48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergedatasets():\n",
    "    reviews = pd.read_csv(\"custom_dataset/reviews.csv\")\n",
    "    metadata = pd.read_csv(\"custom_dataset/metadata.csv\")\n",
    "\n",
    "    merged = pd.merge(reviews, metadata, on= 'parent_asin', how='inner', suffixes=('_review', '_metadata'))\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1874b940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340000, 11)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24815a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314000, 17)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ee7a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaila\\AppData\\Local\\Temp\\ipykernel_21624\\3673331556.py:3: DtypeWarning: Columns (6,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(\"custom_dataset/metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "merged = pd.DataFrame()\n",
    "merged = mergedatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f84c5f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40278, 27)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "14428f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title_review', 'text', 'images_review', 'asin',\n",
       "       'parent_asin', 'user_id', 'timestamp', 'helpful_vote',\n",
       "       'verified_purchase', 'category_review', 'main_category',\n",
       "       'title_metadata', 'average_rating', 'rating_number', 'features',\n",
       "       'description', 'price', 'images_metadata', 'videos', 'store',\n",
       "       'categories', 'details', 'bought_together', 'subtitle', 'author',\n",
       "       'category_metadata'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb43a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9beb8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_path = \"custom_dataset/analysis.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "38feef5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40278, 8)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_columns = {\n",
    "                'main_category': 'category',\n",
    "                'title_metadata': 'item',\n",
    "                'rating': 'rating',\n",
    "                'text': 'reviewText',\n",
    "                'timestamp': 'timestamp',\n",
    "                'rating_number': 'numRating',\n",
    "                'average_rating': 'average_rating',\n",
    "                'helpful_vote':'total_votes'\n",
    "                }\n",
    "\n",
    "merged = merged[list(needed_columns.keys())]\n",
    "merged.rename(columns=needed_columns, inplace=True)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8078b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(analysis_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33196576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7a342cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>numRating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Niseyo new Faux Locs 24 Inch Crochet Hair 6 Pa...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>These were lightweight and soft but much too s...</td>\n",
       "      <td>1634275259292</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               item  rating  \\\n",
       "0  All Beauty  Niseyo new Faux Locs 24 Inch Crochet Hair 6 Pa...     3.0   \n",
       "\n",
       "                                          reviewText      timestamp  \\\n",
       "0  These were lightweight and soft but much too s...  1634275259292   \n",
       "\n",
       "   numRating  average_rating  total_votes  \n",
       "0       62.0             4.3            0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd72ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {1: 0, 2: 0, 4: 1, 5: 1}\n",
    "\n",
    "temp = df[df['rating'] != 3]\n",
    "\n",
    "df.loc[:, 'sentiment'] = temp['rating'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62e0d090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>numRating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Niseyo new Faux Locs 24 Inch Crochet Hair 6 Pa...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>These were lightweight and soft but much too s...</td>\n",
       "      <td>1634275259292</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               item  rating  \\\n",
       "0  All Beauty  Niseyo new Faux Locs 24 Inch Crochet Hair 6 Pa...     3.0   \n",
       "\n",
       "                                          reviewText      timestamp  \\\n",
       "0  These were lightweight and soft but much too s...  1634275259292   \n",
       "\n",
       "   numRating  average_rating  total_votes  sentiment  \n",
       "0       62.0             4.3            0        NaN  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d374aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64772224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37851, 9)\n",
      "category          2632\n",
      "item                 4\n",
      "rating               0\n",
      "reviewText          10\n",
      "timestamp            0\n",
      "numRating          249\n",
      "average_rating       0\n",
      "total_votes          0\n",
      "sentiment            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bc6d9",
   "metadata": {},
   "source": [
    "## Custom popularity metric\n",
    "Popularity Score (PS)\n",
    "PS= 𝛼 × Number of Reviews + 𝛽 × Average Rating+ 𝛾 × Total Votes\n",
    "\n",
    "Where:\n",
    "\n",
    "Number of Reviews = total reviews per item per month (or week).\n",
    "\n",
    "Average Rating = mean of ratings per item per month.\n",
    "\n",
    "Total Votes = sum of votes (helpfulness) on the reviews per item per month.\n",
    "\n",
    "α, β, γ = tunable weights based on what you want to emphasize more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3e0e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.6\n",
    "beta = 0.3\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1134e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"popularity_score\"] = ((alpha * df[\"numRating\"]) + (beta * df[\"average_rating\"]) + (gamma * df[\"total_votes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "211bda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"sentiment\"] == 0, \"popularity_score\"] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f159654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>numRating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>popularity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Organic Bamboo Cotton Ear Swabs by Bali Boo - ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I really like these ear swabs. First they come...</td>\n",
       "      <td>1596473351088</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               item  rating  \\\n",
       "1  All Beauty  Organic Bamboo Cotton Ear Swabs by Bali Boo - ...     5.0   \n",
       "\n",
       "                                          reviewText      timestamp  \\\n",
       "1  I really like these ear swabs. First they come...  1596473351088   \n",
       "\n",
       "   numRating  average_rating  total_votes  sentiment  popularity_score  \n",
       "1       49.0             4.2            0        1.0             30.66  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ba7a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_to_clean = df[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "18c8af20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    I really like these ear swabs. First they come...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_to_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e5009072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0c46ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_df(text):\n",
    "    if isinstance(text, str):  # If the input is a string\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token for token in tokens if token.isalpha()]  # Keep only alphabetic tokens\n",
    "        return tokens\n",
    "    elif isinstance(text, (int, float)):  # If the input is an integer or float\n",
    "        return text  # Return the number as is\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a8493d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    stop_words = (stopwords.words(\"english\"))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "865844a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(tokens):\n",
    "    if tokens is None:\n",
    "        return []  # Return an empty list if tokens is None\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lemma_tokens = [lemma.lemmatize(word) for word in tokens if word is not None]  # Check for None\n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d798a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):  # Check if the input is not a string\n",
    "        return ''  # Return an empty string or handle it as needed\n",
    "    text = clean_html(text)\n",
    "    tokens = tokenize_df(text)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
    "    tokens = lemmatize_text(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3c803d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = reviews_to_clean.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5dde3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = cleaned_reviews.apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip() if isinstance(x, (str, float, int)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e67d1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'reviewText': 'cleanedText'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2cbbc508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'item', 'rating', 'cleanedText', 'timestamp', 'numRating',\n",
       "       'average_rating', 'total_votes', 'sentiment', 'popularity_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8debd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleanedText\"] = cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8bb63237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c59dd68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanedText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>numRating</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>popularity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Organic Bamboo Cotton Ear Swabs by Bali Boo - ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>really like ear swab first come large handy bo...</td>\n",
       "      <td>2020-08-03 16:49:11.088</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               item  rating  \\\n",
       "1  All Beauty  Organic Bamboo Cotton Ear Swabs by Bali Boo - ...     5.0   \n",
       "\n",
       "                                         cleanedText               timestamp  \\\n",
       "1  really like ear swab first come large handy bo... 2020-08-03 16:49:11.088   \n",
       "\n",
       "   numRating  average_rating  total_votes  sentiment  popularity_score  \n",
       "1       49.0             4.2            0        1.0             30.66  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a86eb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"csv's/AnalysisDataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
